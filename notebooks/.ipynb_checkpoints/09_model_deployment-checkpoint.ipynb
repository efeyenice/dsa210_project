{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Game Prediction - Model Deployment and Monitoring\n",
    "\n",
    "This notebook focuses on deploying the model and setting up monitoring. We'll:\n",
    "1. Create a prediction pipeline\n",
    "2. Set up model monitoring\n",
    "3. Create a simple API for predictions\n",
    "4. Document the deployment process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "Import all necessary libraries for model deployment and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Create Prediction Pipeline\n",
    "Load the best model and create a prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class NBAPredictionPipeline:\n",
    "    def __init__(self, model_path, feature_columns_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.feature_columns = pd.read_csv(feature_columns_path)['selected_features'].tolist()\n",
    "        self.predictions_log = []\n",
    "    \n",
    "    def preprocess_input(self, data):\n",
    "        \"\"\"Preprocess input data to match model requirements.\"\"\"\n",
    "        # Ensure all required features are present\n",
    "        for feature in self.feature_columns:\n",
    "            if feature not in data.columns:\n",
    "                raise ValueError(f'Missing required feature: {feature}')\n",
    "        \n",
    "        # Select only required features\n",
    "        return data[self.feature_columns]\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\"Make predictions and log them.\"\"\"\n",
    "        # Preprocess input\n",
    "        X = self.preprocess_input(data)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X)\n",
    "        probabilities = self.model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Log predictions\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "            self.predictions_log.append({\n",
    "                'timestamp': timestamp,\n",
    "                'prediction': int(pred),\n",
    "                'probability': float(prob),\n",
    "                'input_data': X.iloc[i].to_dict()\n",
    "            })\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def save_predictions_log(self, path):\n",
    "        \"\"\"Save prediction logs to file.\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.predictions_log, f, indent=2)\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = NBAPredictionPipeline(\n",
    "    model_path='../models/best_model.joblib',\n",
    "    feature_columns_path='../data/processed/selected_features.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Monitoring Setup\n",
    "Set up monitoring for model performance and data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ModelMonitor:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.performance_metrics = []\n",
    "        self.feature_stats = {}\n",
    "    \n",
    "    def update_metrics(self, y_true, y_pred, y_prob):\n",
    "        \"\"\"Update performance metrics.\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        metrics = {\n",
    "            'timestamp': timestamp,\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'mean_probability': np.mean(y_prob),\n",
    "            'std_probability': np.std(y_prob)\n",
    "        }\n",
    "        self.performance_metrics.append(metrics)\n",
    "    \n",
    "    def update_feature_stats(self, X):\n",
    "        \"\"\"Update feature statistics.\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        for feature in X.columns:\n",
    "            if feature not in self.feature_stats:\n",
    "                self.feature_stats[feature] = []\n",
    "            \n",
    "            self.feature_stats[feature].append({\n",
    "                'timestamp': timestamp,\n",
    "                'mean': float(X[feature].mean()),\n",
    "                'std': float(X[feature].std())\n",
    "            })\n",
    "    \n",
    "    def plot_performance_trends(self):\n",
    "        \"\"\"Plot performance metrics over time.\"\"\"\n",
    "        metrics_df = pd.DataFrame(self.performance_metrics)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(metrics_df['timestamp'], metrics_df['accuracy'], label='Accuracy')\n",
    "        plt.title('Model Accuracy Over Time')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_feature_drift(self, feature):\n",
    "        \"\"\"Plot feature drift over time.\"\"\"\n",
    "        if feature not in self.feature_stats:\n",
    "            print(f'No data available for feature: {feature}')\n",
    "            return\n",
    "        \n",
    "        stats_df = pd.DataFrame(self.feature_stats[feature])\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(stats_df['timestamp'], stats_df['mean'], label='Mean')\n",
    "        plt.fill_between(\n",
    "            stats_df['timestamp'],\n",
    "            stats_df['mean'] - stats_df['std'],\n",
    "            stats_df['mean'] + stats_df['std'],\n",
    "            alpha=0.2\n",
    "        )\n",
    "        plt.title(f'{feature} Distribution Over Time')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def save_monitoring_data(self, base_path):\n",
    "        \"\"\"Save monitoring data to files.\"\"\"\n",
    "        # Save performance metrics\n",
    "        pd.DataFrame(self.performance_metrics).to_csv(\n",
    "            f'{base_path}/performance_metrics.csv', index=False\n",
    "        )\n",
    "        \n",
    "        # Save feature statistics\n",
    "        for feature, stats in self.feature_stats.items():\n",
    "            pd.DataFrame(stats).to_csv(\n",
    "                f'{base_path}/feature_stats_{feature}.csv', index=False\n",
    "            )\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = ModelMonitor(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Simple API\n",
    "Create a simple API for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get input data\n",
    "        data = request.get_json()\n",
    "        input_df = pd.DataFrame(data)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions, probabilities = pipeline.predict(input_df)\n",
    "        \n",
    "        # Update monitoring\n",
    "        monitor.update_feature_stats(input_df)\n",
    "        \n",
    "        # Prepare response\n",
    "        response = {\n",
    "            'predictions': predictions.tolist(),\n",
    "            'probabilities': probabilities.tolist()\n",
    "        }\n",
    "        \n",
    "        return jsonify(response)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Deployment Configuration\n",
    "Save the deployment configuration and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create deployment directory\n",
    "os.makedirs('../deployment', exist_ok=True)\n",
    "\n",
    "# Save API code\n",
    "with open('../deployment/app.py', 'w') as f:\n",
    "    f.write(app.__str__())\n",
    "\n",
    "# Create requirements.txt\n",
    "requirements = [\n",
    "    'flask==2.0.1',\n",
    "    'pandas==1.3.3',\n",
    "    'numpy==1.21.2',\n",
    "    'scikit-learn==0.24.2',\n",
    "    'joblib==1.0.1'\n",
    "]\n",
    "\n",
    "with open('../deployment/requirements.txt', 'w') as f:\n",
    "    f.write('\\n'.join(requirements))\n",
    "\n",
    "# Create README\n",
    "readme = \"\"\"# NBA Game Prediction API\n",
    "\n",
    "This API provides predictions for NBA game outcomes based on team statistics and performance metrics.\n",
    "\n",
    "## Setup\n",
    "1. Install requirements: `pip install -r requirements.txt`\n",
    "2. Run the API: `python app.py`\n",
    "\n",
    "## Usage\n",
    "Send POST requests to `/predict` with game data in JSON format.\n",
    "\n",
    "Example request:\n",
    "```json\n",
    "{\n",
    "    \"NET_RATING\": [5.2],\n",
    "    \"OFF_RATING\": [110.5],\n",
    "    \"DEF_RATING\": [105.3],\n",
    "    \"PACE\": [100.2],\n",
    "    \"WIN_STREAK\": [2],\n",
    "    \"ROLL_WIN_PCT_5\": [0.6],\n",
    "    \"ROLL_WIN_PCT_10\": [0.55],\n",
    "    \"REST_DAYS\": [2],\n",
    "    \"IS_BACK_TO_BACK\": [0]\n",
    "}\n",
    "```\n",
    "\n",
    "## Monitoring\n",
    "The API includes built-in monitoring for:\n",
    "- Model performance metrics\n",
    "- Feature drift detection\n",
    "- Prediction logging\n",
    "\n",
    "## Maintenance\n",
    "Regular maintenance tasks:\n",
    "1. Monitor model performance\n",
    "2. Check for data drift\n",
    "3. Retrain model if necessary\n",
    "4. Update feature statistics\n",
    "\"\"\"\n",
    "\n",
    "with open('../deployment/README.md', 'w') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "print('Deployment files have been saved to ../deployment/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}