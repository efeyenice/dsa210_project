{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Game Prediction - Feature Selection and Engineering\n",
    "\n",
    "This notebook focuses on analyzing feature importance and performing feature selection. We'll:\n",
    "1. Analyze feature importance using multiple methods\n",
    "2. Perform feature selection\n",
    "3. Apply dimensionality reduction techniques\n",
    "4. Create new features if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "Import all necessary libraries for feature selection and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Prepared Data\n",
    "Load the data we prepared in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the prepared data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "print('Training set shape:', X_train.shape)\n",
    "print('Testing set shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis\n",
    "Analyze feature importance using multiple methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 3.1 Correlation Analysis\n",
    "correlations = X_train.corrwith(y_train['TARGET']).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations.plot(kind='bar')\n",
    "plt.title('Feature Correlations with Target')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.2 Random Forest Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train['TARGET'])\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection\n",
    "Select the most important features using statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select top k features using f_classif\n",
    "k = 5  # Number of features to select\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train['TARGET'])\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "print('Selected features:', selected_features)\n",
    "\n",
    "# Save selected features\n",
    "pd.DataFrame({'selected_features': selected_features}).to_csv(\n",
    "    '../data/processed/selected_features.csv', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction\n",
    "Apply PCA to reduce dimensionality while preserving variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Preserve 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print('Original number of features:', X_train.shape[1])\n",
    "print('Number of PCA components:', pca.n_components_)\n",
    "print('Explained variance ratio:', pca.explained_variance_ratio_.sum())\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data\n",
    "Save the processed data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save PCA-transformed data\n",
    "np.save('../data/processed/X_train_pca.npy', X_train_pca)\n",
    "np.save('../data/processed/X_test_pca.npy', X_test_pca)\n",
    "\n",
    "# Save selected features data\n",
    "pd.DataFrame(X_train_selected, columns=selected_features).to_csv(\n",
    "    '../data/processed/X_train_selected.csv', index=False\n",
    ")\n",
    "pd.DataFrame(X_test_selected, columns=selected_features).to_csv(\n",
    "    '../data/processed/X_test_selected.csv', index=False\n",
    ")\n",
    "\n",
    "print('Processed data saved to ../data/processed/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}